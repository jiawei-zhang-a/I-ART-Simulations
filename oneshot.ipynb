{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a96620bc",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e1fafce2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import random\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import scipy.stats as stats\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "03931460",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.736661</td>\n",
              "      <td>2.005429</td>\n",
              "      <td>0.450577</td>\n",
              "      <td>0.533389</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.821195</td>\n",
              "      <td>0.832997</td>\n",
              "      <td>-0.580203</td>\n",
              "      <td>0.090748</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.569464</td>\n",
              "      <td>-0.798814</td>\n",
              "      <td>-2.146912</td>\n",
              "      <td>-2.382507</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061132</td>\n",
              "      <td>-0.388127</td>\n",
              "      <td>1.168400</td>\n",
              "      <td>1.261426</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.196842</td>\n",
              "      <td>1.963949</td>\n",
              "      <td>2.119449</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>-0.141584</td>\n",
              "      <td>-1.854305</td>\n",
              "      <td>0.708134</td>\n",
              "      <td>1.866579</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.161804</td>\n",
              "      <td>-0.623903</td>\n",
              "      <td>0.956548</td>\n",
              "      <td>0.798419</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>3.329909</td>\n",
              "      <td>0.876508</td>\n",
              "      <td>0.816412</td>\n",
              "      <td>1.416870</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.784783</td>\n",
              "      <td>-2.860218</td>\n",
              "      <td>-0.405464</td>\n",
              "      <td>-0.872733</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1.581052</td>\n",
              "      <td>0.642895</td>\n",
              "      <td>0.066556</td>\n",
              "      <td>0.435693</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3    4\n",
              "0      0.736661  2.005429  0.450577  0.533389  0.0\n",
              "1      0.821195  0.832997 -0.580203  0.090748  0.0\n",
              "2     -0.569464 -0.798814 -2.146912 -2.382507  0.0\n",
              "3      0.061132 -0.388127  1.168400  1.261426  0.0\n",
              "4      0.046315  0.196842  1.963949  2.119449  1.0\n",
              "...         ...       ...       ...       ...  ...\n",
              "19995 -0.141584 -1.854305  0.708134  1.866579  0.0\n",
              "19996  0.161804 -0.623903  0.956548  0.798419  0.0\n",
              "19997  3.329909  0.876508  0.816412  1.416870  0.0\n",
              "19998  0.784783 -2.860218 -0.405464 -0.872733  0.0\n",
              "19999  1.581052  0.642895  0.066556  0.435693  1.0\n",
              "\n",
              "[20000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.340853</td>\n",
              "      <td>50.159065</td>\n",
              "      <td>194.350358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.718030</td>\n",
              "      <td>9.031064</td>\n",
              "      <td>10.914054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-56.964812</td>\n",
              "      <td>-8.552965</td>\n",
              "      <td>79.681290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.239406</td>\n",
              "      <td>24.255903</td>\n",
              "      <td>42.844894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>129.091875</td>\n",
              "      <td>108.637595</td>\n",
              "      <td>579.783656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>46.316705</td>\n",
              "      <td>6.580615</td>\n",
              "      <td>2.406937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>4.422518</td>\n",
              "      <td>8.621514</td>\n",
              "      <td>11.607737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>94.014821</td>\n",
              "      <td>242.636826</td>\n",
              "      <td>1565.453405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>-15.618454</td>\n",
              "      <td>-5.524330</td>\n",
              "      <td>47.181496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>54.982110</td>\n",
              "      <td>50.750816</td>\n",
              "      <td>170.571737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0           1            2\n",
              "0       20.340853   50.159065   194.350358\n",
              "1        2.718030    9.031064    10.914054\n",
              "2      -56.964812   -8.552965    79.681290\n",
              "3       44.239406   24.255903    42.844894\n",
              "4      129.091875  108.637595   579.783656\n",
              "...           ...         ...          ...\n",
              "19995   46.316705    6.580615     2.406937\n",
              "19996    4.422518    8.621514    11.607737\n",
              "19997   94.014821  242.636826  1565.453405\n",
              "19998  -15.618454   -5.524330    47.181496\n",
              "19999   54.982110   50.750816   170.571737\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0\n",
              "0      0.0\n",
              "1      0.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "...    ...\n",
              "19995  1.0\n",
              "19996  0.0\n",
              "19997  0.0\n",
              "19998  1.0\n",
              "19999  1.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2\n",
              "0      0.0  0.0  0.0\n",
              "1      0.0  0.0  0.0\n",
              "2      0.0  0.0  1.0\n",
              "3      0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0\n",
              "...    ...  ...  ...\n",
              "19995  0.0  0.0  0.0\n",
              "19996  0.0  0.0  0.0\n",
              "19997  0.0  0.0  0.0\n",
              "19998  0.0  0.0  1.0\n",
              "19999  0.0  0.0  0.0\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "...      ...\n",
              "19995  199.0\n",
              "19996  199.0\n",
              "19997  200.0\n",
              "19998  199.0\n",
              "19999  200.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load data\n",
        "X = np.load(\"/Users/jiaweizhang/research/data/X.npy\")\n",
        "Y = np.load(\"/Users/jiaweizhang/research/data/Y.npy\")\n",
        "Z = np.load(\"/Users/jiaweizhang/research/data/Z.npy\")\n",
        "M = np.load(\"/Users/jiaweizhang/research/data/M.npy\")\n",
        "S = np.load(\"/Users/jiaweizhang/research/data/S.npy\")\n",
        "\n",
        "N = len(X)\n",
        "display(pd.DataFrame(X))\n",
        "display(pd.DataFrame(Y))\n",
        "display(pd.DataFrame(Z))\n",
        "display(pd.DataFrame(M))\n",
        "display(pd.DataFrame(S))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab684f3a",
      "metadata": {},
      "source": [
        "# One shot framework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a542e9ca",
      "metadata": {},
      "source": [
        "### Randomly split one dataframe to two datasets\n",
        "split_df takes a pandas DataFrame as input and randomly splits it into two separate DataFrames with a specified proportion of the data in each split. The function shuffles the indices randomly and splits the DataFrame using the shuffled indices. It returns the two separate DataFrames as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0a65b62e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_df_shuffle(df):\n",
        "    # Set the proportion of data to be split\n",
        "    split_proportion = 0.5\n",
        "\n",
        "    # Set a random seed for reproducibility\n",
        "    random.seed(23)\n",
        "\n",
        "    # Get the indices for the split\n",
        "    indices = df.index.tolist()\n",
        "    num_rows = len(df)\n",
        "    split_index = int(num_rows * split_proportion)\n",
        "\n",
        "    # Shuffle the indices randomly\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Get the randomly selected rows for each split\n",
        "    split1_indices = indices[:split_index]\n",
        "    split2_indices = indices[split_index:]\n",
        "\n",
        "    # Split the original DataFrame into two separate DataFrames\n",
        "    df1 = df.loc[split1_indices]\n",
        "    df2 = df.loc[split2_indices]\n",
        "    \n",
        "    return df1,df2\n",
        "\n",
        "#split based on strata\n",
        "def split_df(df,index_S):\n",
        "\n",
        "    # Sort the groups by the number of rows in each group\n",
        "    sorted_df = df.sort_values(by = index_S, ascending=True)\n",
        "    \n",
        "    # Split the sorted groups into two equal-sized sets of 100 strata each\n",
        "    df_set1 = sorted_df.iloc[:int(N/2),0 : index_S]\n",
        "    df_set2 = sorted_df.iloc[int(N/2):N, 0 : index_S]\n",
        "\n",
        "    #set the index of the two sets from zero to 1\n",
        "    df_set1.index = range(len(df_set1))\n",
        "    df_set2.index = range(len(df_set2))\n",
        "    \n",
        "    # Return the two sets of strata\n",
        "    return df_set1, df_set2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f937fc0",
      "metadata": {},
      "source": [
        "### T-test for T(Z,Y)\n",
        "the Wilcoxon rank sum test\n",
        "$T(\\mathbf{Z}, \\mathbf{Y})=\\sum_{n=1}^{N}Z_{n}\\cdot \\text{rank}(Y_{n})=\\sum_{n=1}^{N}\\{Z_{n}\\cdot \\sum_{n^{\\prime}=1}^{N} \\mathbf{1}(Y_{n}\\geq Y_{n^{\\prime}})\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "785d184a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def T(z,y):\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    n = len(z)\n",
        "    t = 0\n",
        "    #O(N^2) version\n",
        "    \"\"\"\n",
        "    for n in range(N):\n",
        "        rank = sum(1 for n_prime in range(N) if Y[n] >= Y[n_prime])\n",
        "        T += Z[n] * rank\n",
        "    \"\"\"\n",
        "\n",
        "    #O(N*Log(N)) version\n",
        "    my_list = []\n",
        "    for i in range(n):\n",
        "        my_list.append((z[i],y[i]))\n",
        "    sorted_list = sorted(my_list, key=lambda x: x[1])\n",
        "\n",
        "    #Calculate\n",
        "    for i in range(n):\n",
        "        t += sorted_list[i][0] * (i + 1)\n",
        "    \n",
        "    return t\n",
        "\n",
        "def getT(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    y = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    z = df_imputed[:, 0]\n",
        "    \n",
        "    z_tiled = np.tile(z, 3)\n",
        "\n",
        "    # Concatenate the tiled versions of Z together\n",
        "    new_z = np.concatenate((z_tiled,))\n",
        "    new_y = y.flatten()\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    t = T(new_z,new_y)\n",
        "\n",
        "    return t\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a89eab",
      "metadata": {},
      "source": [
        "#### t-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5606fc45",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ttest(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    Y_pred = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    Z_shuffled = df_imputed[:, 0]\n",
        "\n",
        "    # Get the t-statistics for T(Z,Y)\n",
        "    treatment = Y_pred[Z_shuffled == 1].flatten()\n",
        "    control = Y_pred[Z_shuffled == 0].flatten()\n",
        "\n",
        "    t, p = stats.ttest_ind(treatment, control, equal_var=True)\n",
        "\n",
        "    return t,p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963667c1",
      "metadata": {},
      "source": [
        "## One Short Framework \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "koc_huNCosmJ",
      "metadata": {
        "id": "koc_huNCosmJ"
      },
      "outputs": [],
      "source": [
        "def one_shot_test(Z, X, M, Y, S, G1, G2,  L=10000):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked,S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, X.shape[1] + Y.shape[1] + Z.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "    \n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "        \n",
        "    \n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    # calculate exact p-values for each outcome\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "    \n",
        "    return p1, p2\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de036ad6",
      "metadata": {},
      "source": [
        "###  Parallel Computing Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1f0f2f1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def worker(args):\n",
        "    # unpack the arguments\n",
        "    Z, X, M, S, Y_masked, G1, G2, t1_obs, t2_obs, shape, L = args\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "\n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, index_S = X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "\n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "\n",
        "    return p1, p2\n",
        "\n",
        "def one_shot_test_parallel(Z, X, M, Y, S, G1, G2, L=10000, n_jobs=multiprocessing.cpu_count()):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked, S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, index_S = Z.shape[1] + X.shape[1] + Y.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the miassing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "    \n",
        "    # print the number of cores\n",
        "    print(f\"Number of cores: {n_jobs}\")\n",
        "\n",
        "\n",
        "    # simulate data and calculate test statistics in parallel\n",
        "    args_list = [(Z, X, M, Y_masked, S, G1, G2, t1_obs, t2_obs, df.shape, int(L / n_jobs))] * n_jobs\n",
        "    with multiprocessing.Pool(processes=n_jobs) as pool:\n",
        "        p_list = pool.map(worker, args_list)\n",
        "    p1 = np.mean([p[0] for p in p_list], axis=0)\n",
        "    p2 = np.mean([p[1] for p in p_list], axis=0)\n",
        "    \n",
        "    return p1, p2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9594bc22",
      "metadata": {},
      "source": [
        "# Test the framework \n",
        "\n",
        "Test all the machine learning method in single core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06073b6",
      "metadata": {},
      "source": [
        "### (i)  MissForest\n",
        "missForest is an algorithm for data imputation, which is the process of filling in missing values in a dataset. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer.\n",
        "\n",
        "missForest is an implementation of the random forest algorithm for missing data imputation. The algorithm works by building an ensemble of decision trees to predict the missing values in a dataset. The idea behind the algorithm is that decision trees can be used to model the relationship between the variables in a dataset and can be used to predict missing values. The algorithm works by splitting the dataset into several smaller datasets, building decision trees on each of these smaller datasets, and combining the predictions from these decision trees to obtain a final imputed dataset.\n",
        "\n",
        "One of the advantages of using missForest is that it can handle missing values in both categorical and continuous variables. It also handles data with different missing patterns and can be used to impute multiple imputations at once. Additionally, missForest provides a measure of the imputation uncertainty, which is important for correctly interpreting the results of the imputed data. \n",
        "\n",
        "source - https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "105e3d5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null using MissForest\n",
            "Training start\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOne-shot test for Fisher\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms sharp null using MissForest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=2'>3</a>\u001b[0m missForest \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m RandomForestRegressor(),max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=4'>5</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S,G1\u001b[39m=\u001b[39;49mmissForest, G2\u001b[39m=\u001b[39;49mmissForest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 17\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=27'>28</a>\u001b[0m df1, df2 \u001b[39m=\u001b[39m split_df(df, X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m Z\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=29'>30</a>\u001b[0m \u001b[39m# impute the missing values and calculate the observed test statistics in part 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=30'>31</a>\u001b[0m G1\u001b[39m.\u001b[39;49mfit(df1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=31'>32</a>\u001b[0m t1_obs \u001b[39m=\u001b[39m getT(G1, df1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000015?line=33'>34</a>\u001b[0m \u001b[39m# impute the missing values and calculate the observed test statistics in part 2\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:864\u001b[0m, in \u001b[0;36mIterativeImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    848\u001b[0m     \u001b[39m\"\"\"Fit the imputer on `X` and return self.\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \n\u001b[1;32m    850\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:750\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mfor\u001b[39;00m feat_idx \u001b[39min\u001b[39;00m ordered_idx:\n\u001b[1;32m    747\u001b[0m     neighbor_feat_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    748\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    749\u001b[0m     )\n\u001b[0;32m--> 750\u001b[0m     Xt, estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impute_one_feature(\n\u001b[1;32m    751\u001b[0m         Xt,\n\u001b[1;32m    752\u001b[0m         mask_missing_values,\n\u001b[1;32m    753\u001b[0m         feat_idx,\n\u001b[1;32m    754\u001b[0m         neighbor_feat_idx,\n\u001b[1;32m    755\u001b[0m         estimator\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    756\u001b[0m         fit_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    757\u001b[0m     )\n\u001b[1;32m    758\u001b[0m     estimator_triplet \u001b[39m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    759\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimputation_sequence_\u001b[39m.\u001b[39mappend(estimator_triplet)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:401\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    391\u001b[0m     X_train \u001b[39m=\u001b[39m _safe_indexing(\n\u001b[1;32m    392\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    393\u001b[0m         \u001b[39m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    394\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    395\u001b[0m     )\n\u001b[1;32m    396\u001b[0m     y_train \u001b[39m=\u001b[39m _safe_indexing(\n\u001b[1;32m    397\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    398\u001b[0m         \u001b[39m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    399\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    400\u001b[0m     )\n\u001b[0;32m--> 401\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    403\u001b[0m \u001b[39m# if no missing values, don't predict\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(missing_row_mask) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1248\u001b[0m         X,\n\u001b[1;32m   1249\u001b[0m         y,\n\u001b[1;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#MissForest\n",
        "print(\"One-shot test for Fisher's sharp null using MissForest\")\n",
        "missForest = IterativeImputer(estimator = RandomForestRegressor(),max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S,G1=missForest, G2=missForest)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d600ae6f",
      "metadata": {},
      "source": [
        "### (ii) KNN Imputation\n",
        "The basic idea behind KNN for imputation is to replace missing values with the average of the k-nearest neighbors in the feature space. The value of k is determined by the user and can be set using cross-validation. KNN imputation is considered a simple and effective method for imputing missing data, particularly for small amounts of missing values. However, for larger amounts of missing data or for data with a large number of features, more advanced imputation methods may be needed.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ddc839",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null\n",
            "Training start\n",
            "Training end\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOne-shot test for Fisher\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms sharp null\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=2'>3</a>\u001b[0m KNNimputer \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=3'>4</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y,S, G1\u001b[39m=\u001b[39;49mKNNimputer, G2\u001b[39m=\u001b[39;49mKNNimputer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=56'>57</a>\u001b[0m df2_sim \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mDataFrame(Z_2), df2_sim], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=59'>60</a>\u001b[0m \u001b[39m# get the test statistics in part 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetT\u001b[39m(G, df):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=25'>26</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=26'>27</a>\u001b[0m     \u001b[39m# Get the imputed data Y and indicator Z\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=27'>28</a>\u001b[0m     df_imputed \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mtransform(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=28'>29</a>\u001b[0m     y \u001b[39m=\u001b[39m df_imputed[:, Z\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:df_imputed\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=29'>30</a>\u001b[0m     z \u001b[39m=\u001b[39m df_imputed[:, \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py:357\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m# process in fixed-memory chunks\u001b[39;00m\n\u001b[1;32m    349\u001b[0m gen \u001b[39m=\u001b[39m pairwise_distances_chunked(\n\u001b[1;32m    350\u001b[0m     X[row_missing_idx, :],\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     reduce_func\u001b[39m=\u001b[39mprocess_chunk,\n\u001b[1;32m    356\u001b[0m )\n\u001b[0;32m--> 357\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m    358\u001b[0m     \u001b[39m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_empty_features:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 1867\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1869\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1871\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2037\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2039\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:480\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    478\u001b[0m YY \u001b[39m=\u001b[39m Y \u001b[39m*\u001b[39m Y\n\u001b[1;32m    479\u001b[0m distances \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(XX, missing_Y\u001b[39m.\u001b[39mT)\n\u001b[0;32m--> 480\u001b[0m distances \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(missing_X, YY\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    482\u001b[0m np\u001b[39m.\u001b[39mclip(distances, \u001b[39m0\u001b[39m, \u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39mdistances)\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n\u001b[1;32m    485\u001b[0m     \u001b[39m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[39m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
            "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#KNN\n",
        "print(\"One-shot test for Fisher's sharp null using KNN\")\n",
        "KNNimputer = KNNImputer(n_neighbors=7)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y,S, G1=KNNimputer, G2=KNNimputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0d195d",
      "metadata": {},
      "source": [
        "### (iii) BayesianRidge Imputation\n",
        "The BayesianRidge model tries to estimate the coefficients of a linear regression model that best fit the data, taking into account prior knowledge about the coefficients. For data imputation, the missing values are treated as if they are unknown coefficients and are estimated along with the other coefficients during the model fitting process. BayesianRidge can be a good choice for imputation when the relationship between the features is well approximated by a linear model. However, it may not perform well for data sets with more complex relationships between the features.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "62280e80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null\n",
            "Training start\n",
            "Training end\n",
            "Task is 0.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOne-shot test for Fisher\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms sharp null\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=2'>3</a>\u001b[0m BayesianRidge \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mBayesianRidge(),max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=3'>4</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mBayesianRidge, G2\u001b[39m=\u001b[39;49mBayesianRidge)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 21\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=65'>66</a>\u001b[0m \u001b[39m# Calculate the completeness percentage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m l \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 21\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=35'>36</a>\u001b[0m new_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=37'>38</a>\u001b[0m \u001b[39m#the Wilcoxon rank sum test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=38'>39</a>\u001b[0m t \u001b[39m=\u001b[39m T(new_z,new_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 21\u001b[0m in \u001b[0;36mT\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=20'>21</a>\u001b[0m     t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sorted_list[i][\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m (i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000017?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#BayesianRidge\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "BayesianRidge = IterativeImputer(estimator = linear_model.BayesianRidge(),max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=BayesianRidge, G2=BayesianRidge)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012d51ed",
      "metadata": {},
      "source": [
        "### (iv) Nystroem Method for Kernel Approximation\n",
        "The Nystroem method, as implemented in Nystroem is a general method for low-rank approximations of kernels. It achieves this by essentially subsampling the data on which the kernel is evaluated. By default Nystroem uses the rbf kernel, but it can use any kernel function or a precomputed kernel matrix. The number of samples used - which is also the dimensionality of the features computed - is given by the parameter n_components.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e9fc1e20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null using Nystroem Method for Kernel Approximation\n",
            "Training start\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jiaweizhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/Users/jiaweizhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training end\n",
            "Task is 0.00% complete.\n",
            "Task is 1.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=2'>3</a>\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=3'>4</a>\u001b[0m     StandardScaler(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=4'>5</a>\u001b[0m     Nystroem(), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=5'>6</a>\u001b[0m     linear_model\u001b[39m.\u001b[39mRidge()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=7'>8</a>\u001b[0m NystroemKernel \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m pipeline,max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=8'>9</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mNystroemKernel, G2\u001b[39m=\u001b[39;49mNystroemKernel)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=65'>66</a>\u001b[0m \u001b[39m# Calculate the completeness percentage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m l \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=35'>36</a>\u001b[0m new_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=37'>38</a>\u001b[0m \u001b[39m#the Wilcoxon rank sum test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=38'>39</a>\u001b[0m t \u001b[39m=\u001b[39m T(new_z,new_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mT\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=15'>16</a>\u001b[0m     my_list\u001b[39m.\u001b[39mappend((z[i],y[i]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=16'>17</a>\u001b[0m sorted_list \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(my_list, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Nystroem Method for Kernel Approximation\n",
        "print(\"One-shot test for Fisher's sharp null using Nystroem Method for Kernel Approximation\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Nystroem(), \n",
        "    linear_model.Ridge()\n",
        ")\n",
        "NystroemKernel = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NystroemKernel, G2=NystroemKernel)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6658f85a",
      "metadata": {},
      "source": [
        "### (V) XGBoost\n",
        "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\n",
        "\n",
        "\n",
        "source - https://xgboost.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "457c869e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null using XGBoost\n",
            "Training start\n",
            "Training end\n",
            "Task is 0.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=2'>3</a>\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=3'>4</a>\u001b[0m     StandardScaler(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=4'>5</a>\u001b[0m     xgb\u001b[39m.\u001b[39mXGBRegressor()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=6'>7</a>\u001b[0m XGBoost \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m pipeline,max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=7'>8</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mXGBoost, G2\u001b[39m=\u001b[39;49mXGBoost)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=65'>66</a>\u001b[0m \u001b[39m# Calculate the completeness percentage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m l \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=35'>36</a>\u001b[0m new_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=37'>38</a>\u001b[0m \u001b[39m#the Wilcoxon rank sum test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=38'>39</a>\u001b[0m t \u001b[39m=\u001b[39m T(new_z,new_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mT\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=15'>16</a>\u001b[0m     my_list\u001b[39m.\u001b[39mappend((z[i],y[i]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=16'>17</a>\u001b[0m sorted_list \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(my_list, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#XGBoost\n",
        "print(\"One-shot test for Fisher's sharp null using XGBoost\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    xgb.XGBRegressor()\n",
        ")\n",
        "XGBoost = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=XGBoost, G2=XGBoost)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f94fcb",
      "metadata": {},
      "source": [
        "### (vi) NLPRegressor\n",
        "\n",
        "MLPRegressor is a class in the scikit-learn library that implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. It is an artificial neural network model that uses backpropagation to adjust the weights between neurons in order to improve prediction accuracy. MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters. It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b042840a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null using Neural Network\n",
            "Training start\n",
            "Training end\n",
            "Task is 0.00% complete.\n",
            "Task is 1.00% complete.\n",
            "Task is 2.00% complete.\n",
            "Task is 3.00% complete.\n",
            "Task is 4.00% complete.\n",
            "Task is 5.00% complete.\n",
            "Task is 6.00% complete.\n",
            "Task is 7.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=7'>8</a>\u001b[0m NN_imputer \u001b[39m=\u001b[39m IterativeImputer(estimator\u001b[39m=\u001b[39mpipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mmlpregressor\u001b[39m\u001b[39m'\u001b[39m], max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39m# Assuming the one_shot_test() function is already defined\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=10'>11</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mNN_imputer, G2\u001b[39m=\u001b[39;49mNN_imputer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 27\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=65'>66</a>\u001b[0m \u001b[39m# Calculate the completeness percentage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m l \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 27\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetT\u001b[39m(G, df):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=25'>26</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=26'>27</a>\u001b[0m     \u001b[39m# Get the imputed data Y and indicator Z\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=27'>28</a>\u001b[0m     df_imputed \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mtransform(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=28'>29</a>\u001b[0m     y \u001b[39m=\u001b[39m df_imputed[:, Z\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:df_imputed\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000029?line=29'>30</a>\u001b[0m     z \u001b[39m=\u001b[39m df_imputed[:, \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:811\u001b[0m, in \u001b[0;36mIterativeImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m\"\"\"Impute all missing values in `X`.\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \n\u001b[1;32m    796\u001b[0m \u001b[39mNote that this is stochastic, and that if `random_state` is not fixed,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m     The imputed input data.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    809\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 811\u001b[0m X, Xt, mask_missing_values, complete_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initial_imputation(\n\u001b[1;32m    812\u001b[0m     X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    813\u001b[0m )\n\u001b[1;32m    815\u001b[0m X_indicator \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_transform_indicator(complete_mask)\n\u001b[1;32m    817\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39mall(mask_missing_values):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:601\u001b[0m, in \u001b[0;36mIterativeImputer._initial_imputation\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    602\u001b[0m     X,\n\u001b[1;32m    603\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    604\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    605\u001b[0m     reset\u001b[39m=\u001b[39;49min_fit,\n\u001b[1;32m    606\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m _check_inputs_dtype(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing_values)\n\u001b[1;32m    610\u001b[0m X_missing_mask \u001b[39m=\u001b[39m _get_mask(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing_values)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39mdtype)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:918\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m blocks \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(blocks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues\n\u001b[1;32m    920\u001b[0m arr \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    922\u001b[0m     \u001b[39m# non-2D ExtensionArray\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:10883\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  10810\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10811\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  10812\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10880\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  10881\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m> 10883\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1587\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1588\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1589\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1590\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:1654\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1654\u001b[0m     result[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1655\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Neural Network\n",
        "print(\"One-shot test for Fisher's sharp null using Neural Network\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MLPRegressor(hidden_layer_sizes=(100, 100, 100), activation='relu', alpha=0.0001, random_state=0)\n",
        ")\n",
        "\n",
        "NN_imputer = IterativeImputer(estimator=pipeline.named_steps['mlpregressor'], max_iter=10, random_state=0)\n",
        "\n",
        "# Assuming the one_shot_test() function is already defined\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NN_imputer, G2=NN_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7d0135",
      "metadata": {},
      "source": [
        "### (vii) Median and Mean Imputer for data imputation\n",
        "\n",
        "Mean and Median as imputed value\n",
        "\n",
        "source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd88c30",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Median imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Median imputer\")\n",
        "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=median_imputer, G2=median_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2883c426",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Mean imputer\")\n",
        "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=mean_imputer, G2=mean_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d3e2280498d4d0bf5a6eb89edfba29687bb04994b150b07177e7fe6510e612b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

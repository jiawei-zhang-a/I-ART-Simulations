{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a96620bc",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e1fafce2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import random\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import scipy.stats as stats\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "03931460",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.736661</td>\n",
              "      <td>2.005429</td>\n",
              "      <td>0.450577</td>\n",
              "      <td>0.533389</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.821195</td>\n",
              "      <td>0.832997</td>\n",
              "      <td>-0.580203</td>\n",
              "      <td>0.090748</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.569464</td>\n",
              "      <td>-0.798814</td>\n",
              "      <td>-2.146912</td>\n",
              "      <td>-2.382507</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061132</td>\n",
              "      <td>-0.388127</td>\n",
              "      <td>1.168400</td>\n",
              "      <td>1.261426</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.196842</td>\n",
              "      <td>1.963949</td>\n",
              "      <td>2.119449</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>-0.141584</td>\n",
              "      <td>-1.854305</td>\n",
              "      <td>0.708134</td>\n",
              "      <td>1.866579</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.161804</td>\n",
              "      <td>-0.623903</td>\n",
              "      <td>0.956548</td>\n",
              "      <td>0.798419</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>3.329909</td>\n",
              "      <td>0.876508</td>\n",
              "      <td>0.816412</td>\n",
              "      <td>1.416870</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.784783</td>\n",
              "      <td>-2.860218</td>\n",
              "      <td>-0.405464</td>\n",
              "      <td>-0.872733</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1.581052</td>\n",
              "      <td>0.642895</td>\n",
              "      <td>0.066556</td>\n",
              "      <td>0.435693</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3    4\n",
              "0      0.736661  2.005429  0.450577  0.533389  0.0\n",
              "1      0.821195  0.832997 -0.580203  0.090748  0.0\n",
              "2     -0.569464 -0.798814 -2.146912 -2.382507  0.0\n",
              "3      0.061132 -0.388127  1.168400  1.261426  0.0\n",
              "4      0.046315  0.196842  1.963949  2.119449  1.0\n",
              "...         ...       ...       ...       ...  ...\n",
              "19995 -0.141584 -1.854305  0.708134  1.866579  0.0\n",
              "19996  0.161804 -0.623903  0.956548  0.798419  0.0\n",
              "19997  3.329909  0.876508  0.816412  1.416870  0.0\n",
              "19998  0.784783 -2.860218 -0.405464 -0.872733  0.0\n",
              "19999  1.581052  0.642895  0.066556  0.435693  1.0\n",
              "\n",
              "[20000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.340853</td>\n",
              "      <td>50.159065</td>\n",
              "      <td>194.350358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.718030</td>\n",
              "      <td>9.031064</td>\n",
              "      <td>10.914054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-56.964812</td>\n",
              "      <td>-8.552965</td>\n",
              "      <td>79.681290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.239406</td>\n",
              "      <td>24.255903</td>\n",
              "      <td>42.844894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>129.091875</td>\n",
              "      <td>108.637595</td>\n",
              "      <td>579.783656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>46.316705</td>\n",
              "      <td>6.580615</td>\n",
              "      <td>2.406937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>4.422518</td>\n",
              "      <td>8.621514</td>\n",
              "      <td>11.607737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>94.014821</td>\n",
              "      <td>242.636826</td>\n",
              "      <td>1565.453405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>-15.618454</td>\n",
              "      <td>-5.524330</td>\n",
              "      <td>47.181496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>54.982110</td>\n",
              "      <td>50.750816</td>\n",
              "      <td>170.571737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0           1            2\n",
              "0       20.340853   50.159065   194.350358\n",
              "1        2.718030    9.031064    10.914054\n",
              "2      -56.964812   -8.552965    79.681290\n",
              "3       44.239406   24.255903    42.844894\n",
              "4      129.091875  108.637595   579.783656\n",
              "...           ...         ...          ...\n",
              "19995   46.316705    6.580615     2.406937\n",
              "19996    4.422518    8.621514    11.607737\n",
              "19997   94.014821  242.636826  1565.453405\n",
              "19998  -15.618454   -5.524330    47.181496\n",
              "19999   54.982110   50.750816   170.571737\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0\n",
              "0      0.0\n",
              "1      0.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "...    ...\n",
              "19995  1.0\n",
              "19996  0.0\n",
              "19997  0.0\n",
              "19998  1.0\n",
              "19999  1.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2\n",
              "0      0.0  0.0  0.0\n",
              "1      0.0  0.0  0.0\n",
              "2      0.0  0.0  1.0\n",
              "3      0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0\n",
              "...    ...  ...  ...\n",
              "19995  0.0  0.0  0.0\n",
              "19996  0.0  0.0  0.0\n",
              "19997  0.0  0.0  0.0\n",
              "19998  0.0  0.0  1.0\n",
              "19999  0.0  0.0  0.0\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "...      ...\n",
              "19995  199.0\n",
              "19996  199.0\n",
              "19997  200.0\n",
              "19998  199.0\n",
              "19999  200.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load data\n",
        "X = np.load(\"/Users/jiaweizhang/research/data/X.npy\")\n",
        "Y = np.load(\"/Users/jiaweizhang/research/data/Y.npy\")\n",
        "Z = np.load(\"/Users/jiaweizhang/research/data/Z.npy\")\n",
        "M = np.load(\"/Users/jiaweizhang/research/data/M.npy\")\n",
        "S = np.load(\"/Users/jiaweizhang/research/data/S.npy\")\n",
        "\n",
        "N = len(X)\n",
        "display(pd.DataFrame(X))\n",
        "display(pd.DataFrame(Y))\n",
        "display(pd.DataFrame(Z))\n",
        "display(pd.DataFrame(M))\n",
        "display(pd.DataFrame(S))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab684f3a",
      "metadata": {},
      "source": [
        "# One shot framework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a542e9ca",
      "metadata": {},
      "source": [
        "### Randomly split one dataframe to two datasets\n",
        "split_df takes a pandas DataFrame as input and randomly splits it into two separate DataFrames with a specified proportion of the data in each split. The function shuffles the indices randomly and splits the DataFrame using the shuffled indices. It returns the two separate DataFrames as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0a65b62e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_df_shuffle(df):\n",
        "    # Set the proportion of data to be split\n",
        "    split_proportion = 0.5\n",
        "\n",
        "    # Set a random seed for reproducibility\n",
        "    random.seed(23)\n",
        "\n",
        "    # Get the indices for the split\n",
        "    indices = df.index.tolist()\n",
        "    num_rows = len(df)\n",
        "    split_index = int(num_rows * split_proportion)\n",
        "\n",
        "    # Shuffle the indices randomly\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Get the randomly selected rows for each split\n",
        "    split1_indices = indices[:split_index]\n",
        "    split2_indices = indices[split_index:]\n",
        "\n",
        "    # Split the original DataFrame into two separate DataFrames\n",
        "    df1 = df.loc[split1_indices]\n",
        "    df2 = df.loc[split2_indices]\n",
        "    \n",
        "    return df1,df2\n",
        "\n",
        "#split based on strata\n",
        "def split_df(df,index_S):\n",
        "\n",
        "    # Sort the groups by the number of rows in each group\n",
        "    sorted_df = df.sort_values(by = index_S, ascending=True)\n",
        "    \n",
        "    # Split the sorted groups into two equal-sized sets of 100 strata each\n",
        "    df_set1 = sorted_df.iloc[:int(N/2),0 : index_S]\n",
        "    df_set2 = sorted_df.iloc[int(N/2):N, 0 : index_S]\n",
        "\n",
        "    #set the index of the two sets from zero to 1\n",
        "    df_set1.index = range(len(df_set1))\n",
        "    df_set2.index = range(len(df_set2))\n",
        "    \n",
        "    # Return the two sets of strata\n",
        "    return df_set1, df_set2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f937fc0",
      "metadata": {},
      "source": [
        "### T-test for T(Z,Y)\n",
        "the Wilcoxon rank sum test\n",
        "$T(\\mathbf{Z}, \\mathbf{Y})=\\sum_{n=1}^{N}Z_{n}\\cdot \\text{rank}(Y_{n})=\\sum_{n=1}^{N}\\{Z_{n}\\cdot \\sum_{n^{\\prime}=1}^{N} \\mathbf{1}(Y_{n}\\geq Y_{n^{\\prime}})\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "785d184a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def T(z,y):\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    n = len(z)\n",
        "    t = 0\n",
        "    #O(N^2) version\n",
        "    \"\"\"\n",
        "    for n in range(N):\n",
        "        rank = sum(1 for n_prime in range(N) if Y[n] >= Y[n_prime])\n",
        "        T += Z[n] * rank\n",
        "    \"\"\"\n",
        "\n",
        "    #O(N*Log(N)) version\n",
        "    my_list = []\n",
        "    for i in range(n):\n",
        "        my_list.append((z[i],y[i]))\n",
        "    sorted_list = sorted(my_list, key=lambda x: x[1])\n",
        "\n",
        "    #Calculate\n",
        "    for i in range(n):\n",
        "        t += sorted_list[i][0] * (i + 1)\n",
        "    \n",
        "    return t\n",
        "\n",
        "def getT(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    y = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    z = df_imputed[:, 0]\n",
        "    \n",
        "    z_tiled = np.tile(z, 3)\n",
        "\n",
        "    # Concatenate the tiled versions of Z together\n",
        "    new_z = np.concatenate((z_tiled,))\n",
        "    new_y = y.flatten()\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    t = T(new_z,new_y)\n",
        "\n",
        "    return t\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a89eab",
      "metadata": {},
      "source": [
        "#### t-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5606fc45",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ttest(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    Y_pred = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    Z_shuffled = df_imputed[:, 0]\n",
        "\n",
        "    # Get the t-statistics for T(Z,Y)\n",
        "    treatment = Y_pred[Z_shuffled == 1].flatten()\n",
        "    control = Y_pred[Z_shuffled == 0].flatten()\n",
        "\n",
        "    t, p = stats.ttest_ind(treatment, control, equal_var=True)\n",
        "\n",
        "    return t,p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963667c1",
      "metadata": {},
      "source": [
        "## One Short Framework \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "koc_huNCosmJ",
      "metadata": {
        "id": "koc_huNCosmJ"
      },
      "outputs": [],
      "source": [
        "def one_shot_test(Z, X, M, Y, S, G1, G2,  L=10000):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked,S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, X.shape[1] + Y.shape[1] + Z.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "    \n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "        \n",
        "    \n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    # calculate exact p-values for each outcome\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "    \n",
        "    return p1, p2\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de036ad6",
      "metadata": {},
      "source": [
        "###  Parallel Computing Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1f0f2f1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def worker(args):\n",
        "    # unpack the arguments\n",
        "    Z, X, M, S, Y_masked, G1, G2, t1_obs, t2_obs, shape, L = args\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "\n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, index_S = X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "\n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "\n",
        "    return p1, p2\n",
        "\n",
        "def one_shot_test_parallel(Z, X, M, Y, S, G1, G2, L=10000, n_jobs=multiprocessing.cpu_count()):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked, S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, index_S = Z.shape[1] + X.shape[1] + Y.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the miassing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "    \n",
        "    # print the number of cores\n",
        "    print(f\"Number of cores: {n_jobs}\")\n",
        "\n",
        "\n",
        "    # simulate data and calculate test statistics in parallel\n",
        "    args_list = [(Z, X, M, Y_masked, S, G1, G2, t1_obs, t2_obs, df.shape, int(L / n_jobs))] * n_jobs\n",
        "    with multiprocessing.Pool(processes=n_jobs) as pool:\n",
        "        p_list = pool.map(worker, args_list)\n",
        "    p1 = np.mean([p[0] for p in p_list], axis=0)\n",
        "    p2 = np.mean([p[1] for p in p_list], axis=0)\n",
        "    \n",
        "    return p1, p2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9594bc22",
      "metadata": {},
      "source": [
        "# Test the framework \n",
        "\n",
        "Test all the machine learning method in single core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06073b6",
      "metadata": {},
      "source": [
        "### (i)  MissForest\n",
        "missForest is an algorithm for data imputation, which is the process of filling in missing values in a dataset. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer.\n",
        "\n",
        "missForest is an implementation of the random forest algorithm for missing data imputation. The algorithm works by building an ensemble of decision trees to predict the missing values in a dataset. The idea behind the algorithm is that decision trees can be used to model the relationship between the variables in a dataset and can be used to predict missing values. The algorithm works by splitting the dataset into several smaller datasets, building decision trees on each of these smaller datasets, and combining the predictions from these decision trees to obtain a final imputed dataset.\n",
        "\n",
        "One of the advantages of using missForest is that it can handle missing values in both categorical and continuous variables. It also handles data with different missing patterns and can be used to impute multiple imputations at once. Additionally, missForest provides a measure of the imputation uncertainty, which is important for correctly interpreting the results of the imputed data. \n",
        "\n",
        "source - https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "105e3d5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#MissForest\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "missForest = IterativeImputer(estimator = RandomForestRegressor(),max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S,G1=missForest, G2=missForest)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d600ae6f",
      "metadata": {},
      "source": [
        "### (ii) KNN Imputation\n",
        "The basic idea behind KNN for imputation is to replace missing values with the average of the k-nearest neighbors in the feature space. The value of k is determined by the user and can be set using cross-validation. KNN imputation is considered a simple and effective method for imputing missing data, particularly for small amounts of missing values. However, for larger amounts of missing data or for data with a large number of features, more advanced imputation methods may be needed.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "52ddc839",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null\n",
            "Training start\n",
            "Training end\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOne-shot test for Fisher\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms sharp null\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=2'>3</a>\u001b[0m KNNimputer \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=3'>4</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y,S, G1\u001b[39m=\u001b[39;49mKNNimputer, G2\u001b[39m=\u001b[39;49mKNNimputer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 2:\u001b[39m\u001b[39m\"\u001b[39m, p2)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=56'>57</a>\u001b[0m df2_sim \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mDataFrame(Z_2), df2_sim], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=59'>60</a>\u001b[0m \u001b[39m# get the test statistics in part 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 19\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetT\u001b[39m(G, df):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=25'>26</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=26'>27</a>\u001b[0m     \u001b[39m# Get the imputed data Y and indicator Z\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=27'>28</a>\u001b[0m     df_imputed \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mtransform(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=28'>29</a>\u001b[0m     y \u001b[39m=\u001b[39m df_imputed[:, Z\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:df_imputed\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000016?line=29'>30</a>\u001b[0m     z \u001b[39m=\u001b[39m df_imputed[:, \u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py:357\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m# process in fixed-memory chunks\u001b[39;00m\n\u001b[1;32m    349\u001b[0m gen \u001b[39m=\u001b[39m pairwise_distances_chunked(\n\u001b[1;32m    350\u001b[0m     X[row_missing_idx, :],\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     reduce_func\u001b[39m=\u001b[39mprocess_chunk,\n\u001b[1;32m    356\u001b[0m )\n\u001b[0;32m--> 357\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m    358\u001b[0m     \u001b[39m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_empty_features:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 1867\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1869\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1871\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2037\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2039\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:480\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    478\u001b[0m YY \u001b[39m=\u001b[39m Y \u001b[39m*\u001b[39m Y\n\u001b[1;32m    479\u001b[0m distances \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(XX, missing_Y\u001b[39m.\u001b[39mT)\n\u001b[0;32m--> 480\u001b[0m distances \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(missing_X, YY\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    482\u001b[0m np\u001b[39m.\u001b[39mclip(distances, \u001b[39m0\u001b[39m, \u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39mdistances)\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n\u001b[1;32m    485\u001b[0m     \u001b[39m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[39m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
            "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#KNNimputer\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "KNNimputer = KNNImputer(n_neighbors=7)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y,S, G1=KNNimputer, G2=KNNimputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0d195d",
      "metadata": {},
      "source": [
        "### (iii) BayesianRidge Imputation\n",
        "The BayesianRidge model tries to estimate the coefficients of a linear regression model that best fit the data, taking into account prior knowledge about the coefficients. For data imputation, the missing values are treated as if they are unknown coefficients and are estimated along with the other coefficients during the model fitting process. BayesianRidge can be a good choice for imputation when the relationship between the features is well approximated by a linear model. However, it may not perform well for data sets with more complex relationships between the features.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62280e80",
      "metadata": {},
      "outputs": [],
      "source": [
        "#BayesianRidge\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "BayesianRidge = IterativeImputer(estimator = linear_model.BayesianRidge(),max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=BayesianRidge, G2=BayesianRidge)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012d51ed",
      "metadata": {},
      "source": [
        "### (iv) Nystroem Method for Kernel Approximation\n",
        "The Nystroem method, as implemented in Nystroem is a general method for low-rank approximations of kernels. It achieves this by essentially subsampling the data on which the kernel is evaluated. By default Nystroem uses the rbf kernel, but it can use any kernel function or a precomputed kernel matrix. The number of samples used - which is also the dimensionality of the features computed - is given by the parameter n_components.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e9fc1e20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null\n",
            "Training start\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jiaweizhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/Users/jiaweizhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training end\n",
            "Task is 0.00% complete.\n",
            "Task is 1.00% complete.\n",
            "Task is 2.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=2'>3</a>\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=3'>4</a>\u001b[0m     StandardScaler(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=4'>5</a>\u001b[0m     Nystroem(), linear_model\u001b[39m.\u001b[39mRidge()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=6'>7</a>\u001b[0m NystroemKernel \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m pipeline,max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=7'>8</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mNystroemKernel, G2\u001b[39m=\u001b[39;49mNystroemKernel)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=56'>57</a>\u001b[0m df2_sim \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mDataFrame(Z_2), df2_sim], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=59'>60</a>\u001b[0m \u001b[39m# get the test statistics in part 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=35'>36</a>\u001b[0m new_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=37'>38</a>\u001b[0m \u001b[39m#the Wilcoxon rank sum test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=38'>39</a>\u001b[0m t \u001b[39m=\u001b[39m T(new_z,new_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mT\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=15'>16</a>\u001b[0m     my_list\u001b[39m.\u001b[39mappend((z[i],y[i]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=16'>17</a>\u001b[0m sorted_list \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(my_list, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 23\u001b[0m in \u001b[0;36mT.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=15'>16</a>\u001b[0m     my_list\u001b[39m.\u001b[39mappend((z[i],y[i]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=16'>17</a>\u001b[0m sorted_list \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(my_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000020?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Nystroem Method for Kernel Approximation\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Nystroem(), \n",
        "    linear_model.Ridge()\n",
        ")\n",
        "NystroemKernel = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NystroemKernel, G2=NystroemKernel)\n",
        "print(\"p-values for part 1:\", p1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6658f85a",
      "metadata": {},
      "source": [
        "### (V) XGBoost\n",
        "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\n",
        "\n",
        "\n",
        "source - https://xgboost.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "457c869e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null\n",
            "Training start\n",
            "Training end\n",
            "Task is 0.00% complete.\n",
            "Task is 1.00% complete.\n",
            "Task is 2.00% complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=2'>3</a>\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=3'>4</a>\u001b[0m     \u001b[39m#StandardScaler(),\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=4'>5</a>\u001b[0m     xgb\u001b[39m.\u001b[39mXGBRegressor()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=6'>7</a>\u001b[0m XGBoost \u001b[39m=\u001b[39m IterativeImputer(estimator \u001b[39m=\u001b[39m pipeline,max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=7'>8</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m one_shot_test(Z, X, M, Y, S, G1\u001b[39m=\u001b[39;49mXGBoost, G2\u001b[39m=\u001b[39;49mXGBoost)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mp-values for part 1:\u001b[39m\u001b[39m\"\u001b[39m, p1)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=56'>57</a>\u001b[0m df2_sim \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mDataFrame(Z_2), df2_sim], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=59'>60</a>\u001b[0m \u001b[39m# get the test statistics in part 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=60'>61</a>\u001b[0m t1_sim[l] \u001b[39m=\u001b[39m getT(G2, df1_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=62'>63</a>\u001b[0m \u001b[39m# get the test statistics in part 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=63'>64</a>\u001b[0m t2_sim[l] \u001b[39m=\u001b[39m getT(G1, df2_sim)\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=35'>36</a>\u001b[0m new_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=37'>38</a>\u001b[0m \u001b[39m#the Wilcoxon rank sum test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=38'>39</a>\u001b[0m t \u001b[39m=\u001b[39m T(new_z,new_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[1;32m/Users/jiaweizhang/research/oneshot.ipynb Cell 25\u001b[0m in \u001b[0;36mT\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=18'>19</a>\u001b[0m \u001b[39m#Calculate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=20'>21</a>\u001b[0m     t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sorted_list[i][\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m (i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaweizhang/research/oneshot.ipynb#ch0000027?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#XGBoost\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    xgb.XGBRegressor()\n",
        ")\n",
        "XGBoost = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=XGBoost, G2=XGBoost)\n",
        "print(\"p-values for part 1:\", p1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f94fcb",
      "metadata": {},
      "source": [
        "### (vi) NLPRegressor\n",
        "\n",
        "MLPRegressor is a class in the scikit-learn library that implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. It is an artificial neural network model that uses backpropagation to adjust the weights between neurons in order to improve prediction accuracy. MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters. It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b042840a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MLPRegressor(hidden_layer_sizes=(100, 100, 100), activation='relu', alpha=0.0001, random_state=0)\n",
        ")\n",
        "\n",
        "NN_imputer = IterativeImputer(estimator=pipeline.named_steps['mlpregressor'], max_iter=10, random_state=0)\n",
        "\n",
        "# Assuming the one_shot_test() function is already defined\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NN_imputer, G2=NN_imputer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7d0135",
      "metadata": {},
      "source": [
        "### (vii) Median and Mean Imputer for data imputation\n",
        "\n",
        "\n",
        "source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd88c30",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Median imputer\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=median_imputer, G2=median_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2883c426",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean imputer\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=mean_imputer, G2=mean_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d3e2280498d4d0bf5a6eb89edfba29687bb04994b150b07177e7fe6510e612b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

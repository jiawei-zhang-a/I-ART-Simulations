{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a96620bc",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e1fafce2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import random\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import scipy.stats as stats\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03931460",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.981770</td>\n",
              "      <td>-0.251813</td>\n",
              "      <td>-0.759265</td>\n",
              "      <td>-2.174064</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.221323</td>\n",
              "      <td>-1.151682</td>\n",
              "      <td>0.029161</td>\n",
              "      <td>1.107834</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.744473</td>\n",
              "      <td>0.373165</td>\n",
              "      <td>1.073115</td>\n",
              "      <td>1.713880</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.338039</td>\n",
              "      <td>1.880270</td>\n",
              "      <td>-0.630888</td>\n",
              "      <td>-0.832539</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.747007</td>\n",
              "      <td>-1.175739</td>\n",
              "      <td>0.071529</td>\n",
              "      <td>0.313842</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>-1.075212</td>\n",
              "      <td>0.356284</td>\n",
              "      <td>0.188095</td>\n",
              "      <td>0.608306</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>1.100295</td>\n",
              "      <td>-0.411935</td>\n",
              "      <td>-0.069896</td>\n",
              "      <td>-0.232181</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>1.514623</td>\n",
              "      <td>0.329402</td>\n",
              "      <td>1.327177</td>\n",
              "      <td>1.405978</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.407197</td>\n",
              "      <td>-1.394913</td>\n",
              "      <td>-0.000789</td>\n",
              "      <td>0.542119</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.099463</td>\n",
              "      <td>-1.552645</td>\n",
              "      <td>-1.387961</td>\n",
              "      <td>0.524931</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3    4\n",
              "0      0.981770 -0.251813 -0.759265 -2.174064  0.0\n",
              "1     -0.221323 -1.151682  0.029161  1.107834  0.0\n",
              "2      1.744473  0.373165  1.073115  1.713880  1.0\n",
              "3      0.338039  1.880270 -0.630888 -0.832539  1.0\n",
              "4      0.747007 -1.175739  0.071529  0.313842  0.0\n",
              "...         ...       ...       ...       ...  ...\n",
              "19995 -1.075212  0.356284  0.188095  0.608306  1.0\n",
              "19996  1.100295 -0.411935 -0.069896 -0.232181  1.0\n",
              "19997  1.514623  0.329402  1.327177  1.405978  0.0\n",
              "19998  0.407197 -1.394913 -0.000789  0.542119  1.0\n",
              "19999  0.099463 -1.552645 -1.387961  0.524931  1.0\n",
              "\n",
              "[20000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.773007</td>\n",
              "      <td>-4.307684</td>\n",
              "      <td>28.546945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23.131155</td>\n",
              "      <td>-0.293310</td>\n",
              "      <td>0.276195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111.466797</td>\n",
              "      <td>111.979334</td>\n",
              "      <td>641.841480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.234558</td>\n",
              "      <td>24.110527</td>\n",
              "      <td>39.479267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.311598</td>\n",
              "      <td>3.856759</td>\n",
              "      <td>1.343088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>34.241948</td>\n",
              "      <td>6.935492</td>\n",
              "      <td>8.770458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>31.320879</td>\n",
              "      <td>16.715269</td>\n",
              "      <td>17.345786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>78.006079</td>\n",
              "      <td>71.204181</td>\n",
              "      <td>312.519088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>32.060799</td>\n",
              "      <td>10.197790</td>\n",
              "      <td>1.355323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>18.524768</td>\n",
              "      <td>-2.967232</td>\n",
              "      <td>9.418364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0           1           2\n",
              "0        2.773007   -4.307684   28.546945\n",
              "1       23.131155   -0.293310    0.276195\n",
              "2      111.466797  111.979334  641.841480\n",
              "3       50.234558   24.110527   39.479267\n",
              "4       21.311598    3.856759    1.343088\n",
              "...           ...         ...         ...\n",
              "19995   34.241948    6.935492    8.770458\n",
              "19996   31.320879   16.715269   17.345786\n",
              "19997   78.006079   71.204181  312.519088\n",
              "19998   32.060799   10.197790    1.355323\n",
              "19999   18.524768   -2.967232    9.418364\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0\n",
              "0      1.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "...    ...\n",
              "19995  1.0\n",
              "19996  1.0\n",
              "19997  1.0\n",
              "19998  1.0\n",
              "19999  1.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2\n",
              "0      0.0  0.0  1.0\n",
              "1      0.0  0.0  0.0\n",
              "2      0.0  0.0  0.0\n",
              "3      0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0\n",
              "...    ...  ...  ...\n",
              "19995  0.0  0.0  0.0\n",
              "19996  0.0  0.0  0.0\n",
              "19997  0.0  0.0  0.0\n",
              "19998  0.0  0.0  0.0\n",
              "19999  0.0  0.0  0.0\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "...      ...\n",
              "19995  199.0\n",
              "19996  199.0\n",
              "19997  199.0\n",
              "19998  199.0\n",
              "19999  200.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load data\n",
        "X = np.load(\"/Users/jiaweizhang/research/data/X.npy\")\n",
        "Y = np.load(\"/Users/jiaweizhang/research/data/Y.npy\")\n",
        "Z = np.load(\"/Users/jiaweizhang/research/data/Z.npy\")\n",
        "M = np.load(\"/Users/jiaweizhang/research/data/M.npy\")\n",
        "S = np.load(\"/Users/jiaweizhang/research/data/S.npy\")\n",
        "\n",
        "N = len(X)\n",
        "display(pd.DataFrame(X))\n",
        "display(pd.DataFrame(Y))\n",
        "display(pd.DataFrame(Z))\n",
        "display(pd.DataFrame(M))\n",
        "display(pd.DataFrame(S))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab684f3a",
      "metadata": {},
      "source": [
        "# One shot framework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a542e9ca",
      "metadata": {},
      "source": [
        "### Randomly split one dataframe to two datasets\n",
        "split_df takes a pandas DataFrame as input and randomly splits it into two separate DataFrames with a specified proportion of the data in each split. The function shuffles the indices randomly and splits the DataFrame using the shuffled indices. It returns the two separate DataFrames as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a65b62e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_df_shuffle(df):\n",
        "    # Set the proportion of data to be split\n",
        "    split_proportion = 0.5\n",
        "\n",
        "    # Set a random seed for reproducibility\n",
        "    random.seed(23)\n",
        "\n",
        "    # Get the indices for the split\n",
        "    indices = df.index.tolist()\n",
        "    num_rows = len(df)\n",
        "    split_index = int(num_rows * split_proportion)\n",
        "\n",
        "    # Shuffle the indices randomly\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Get the randomly selected rows for each split\n",
        "    split1_indices = indices[:split_index]\n",
        "    split2_indices = indices[split_index:]\n",
        "\n",
        "    # Split the original DataFrame into two separate DataFrames\n",
        "    df1 = df.loc[split1_indices]\n",
        "    df2 = df.loc[split2_indices]\n",
        "    \n",
        "    return df1,df2\n",
        "\n",
        "#split based on strata\n",
        "def split_df(df,index_S):\n",
        "\n",
        "    # Sort the groups by the number of rows in each group\n",
        "    sorted_df = df.sort_values(by = index_S, ascending=True)\n",
        "    \n",
        "    # Split the sorted groups into two equal-sized sets of 100 strata each\n",
        "    df_set1 = sorted_df.iloc[:int(N/2),0 : index_S]\n",
        "    df_set2 = sorted_df.iloc[int(N/2):N, 0 : index_S]\n",
        "\n",
        "    #set the index of the two sets from zero to 1\n",
        "    df_set1.index = range(len(df_set1))\n",
        "    df_set2.index = range(len(df_set2))\n",
        "    \n",
        "    # Return the two sets of strata\n",
        "    return df_set1, df_set2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f937fc0",
      "metadata": {},
      "source": [
        "### T-test for T(Z,Y)\n",
        "the Wilcoxon rank sum test\n",
        "$T(\\mathbf{Z}, \\mathbf{Y})=\\sum_{n=1}^{N}Z_{n}\\cdot \\text{rank}(Y_{n})=\\sum_{n=1}^{N}\\{Z_{n}\\cdot \\sum_{n^{\\prime}=1}^{N} \\mathbf{1}(Y_{n}\\geq Y_{n^{\\prime}})\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785d184a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def T(z,y):\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    n = len(z)\n",
        "    t = 0\n",
        "    #O(N^2) version\n",
        "    \"\"\"\n",
        "    for n in range(N):\n",
        "        rank = sum(1 for n_prime in range(N) if Y[n] >= Y[n_prime])\n",
        "        T += Z[n] * rank\n",
        "    \"\"\"\n",
        "\n",
        "    #O(N*Log(N)) version\n",
        "    my_list = []\n",
        "    for i in range(n):\n",
        "        my_list.append((z[i],y[i]))\n",
        "    sorted_list = sorted(my_list, key=lambda x: x[1])\n",
        "\n",
        "    #Calculate\n",
        "    for i in range(n):\n",
        "        t += sorted_list[i][0] * (i + 1)\n",
        "    \n",
        "    return t\n",
        "\n",
        "def getT(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    y = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    z = df_imputed[:, 0]\n",
        "    \n",
        "    z_tiled = np.tile(z, 3)\n",
        "\n",
        "    # Concatenate the tiled versions of Z together\n",
        "    new_z = np.concatenate((z_tiled,))\n",
        "    new_y = y.flatten()\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    t = T(new_z,new_y)\n",
        "\n",
        "    return t\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a89eab",
      "metadata": {},
      "source": [
        "#### t-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5606fc45",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ttest(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    Y_pred = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    Z_shuffled = df_imputed[:, 0]\n",
        "\n",
        "    # Get the t-statistics for T(Z,Y)\n",
        "    treatment = Y_pred[Z_shuffled == 1].flatten()\n",
        "    control = Y_pred[Z_shuffled == 0].flatten()\n",
        "\n",
        "    t, p = stats.ttest_ind(treatment, control, equal_var=True)\n",
        "\n",
        "    return t,p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963667c1",
      "metadata": {},
      "source": [
        "## One Short Framework \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "koc_huNCosmJ",
      "metadata": {
        "id": "koc_huNCosmJ"
      },
      "outputs": [],
      "source": [
        "def one_shot_test(Z, X, M, Y, S, G1, G2,  L=10000, verbose = False):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "\n",
        "    #print train start\n",
        "    if verbose:\n",
        "        print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked,S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, X.shape[1] + Y.shape[1] + Z.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    if verbose:\n",
        "        print(\"Training end\")\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "    \n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "        \n",
        "    \n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100\n",
        "            if verbose:  \n",
        "                print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    # calculate exact p-values for each outcome\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "    \n",
        "    return p1, p2\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de036ad6",
      "metadata": {},
      "source": [
        "###  Parallel Computing Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0f2f1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def worker(args):\n",
        "    # unpack the arguments\n",
        "    Z, X, M, S, Y_masked, G1, G2, t1_obs, t2_obs, shape, L = args\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "\n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, index_S = X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "\n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "\n",
        "    return p1, p2\n",
        "\n",
        "def one_shot_test_parallel(Z, X, M, Y, S, G1, G2, L=10000, n_jobs=multiprocessing.cpu_count()):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked, S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, index_S = Z.shape[1] + X.shape[1] + Y.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df1)\n",
        "\n",
        "    # impute the miassing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df2)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "    \n",
        "    # print the number of cores\n",
        "    print(f\"Number of cores: {n_jobs}\")\n",
        "\n",
        "\n",
        "    # simulate data and calculate test statistics in parallel\n",
        "    args_list = [(Z, X, M, Y_masked, S, G1, G2, t1_obs, t2_obs, df.shape, int(L / n_jobs))] * n_jobs\n",
        "    with multiprocessing.Pool(processes=n_jobs) as pool:\n",
        "        p_list = pool.map(worker, args_list)\n",
        "    p1 = np.mean([p[0] for p in p_list], axis=0)\n",
        "    p2 = np.mean([p[1] for p in p_list], axis=0)\n",
        "    \n",
        "    return p1, p2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9594bc22",
      "metadata": {},
      "source": [
        "# Test the framework \n",
        "\n",
        "Test all the machine learning method in single core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06073b6",
      "metadata": {},
      "source": [
        "### (i)  MissForest\n",
        "missForest is an algorithm for data imputation, which is the process of filling in missing values in a dataset. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer.\n",
        "\n",
        "missForest is an implementation of the random forest algorithm for missing data imputation. The algorithm works by building an ensemble of decision trees to predict the missing values in a dataset. The idea behind the algorithm is that decision trees can be used to model the relationship between the variables in a dataset and can be used to predict missing values. The algorithm works by splitting the dataset into several smaller datasets, building decision trees on each of these smaller datasets, and combining the predictions from these decision trees to obtain a final imputed dataset.\n",
        "\n",
        "One of the advantages of using missForest is that it can handle missing values in both categorical and continuous variables. It also handles data with different missing patterns and can be used to impute multiple imputations at once. Additionally, missForest provides a measure of the imputation uncertainty, which is important for correctly interpreting the results of the imputed data. \n",
        "\n",
        "source - https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "105e3d5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#MissForest\n",
        "print(\"One-shot test for Fisher's sharp null using MissForest\")\n",
        "missForest = IterativeImputer(estimator = RandomForestRegressor(),max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S,G1=missForest, G2=missForest)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d600ae6f",
      "metadata": {},
      "source": [
        "### (ii) KNN Imputation\n",
        "The basic idea behind KNN for imputation is to replace missing values with the average of the k-nearest neighbors in the feature space. The value of k is determined by the user and can be set using cross-validation. KNN imputation is considered a simple and effective method for imputing missing data, particularly for small amounts of missing values. However, for larger amounts of missing data or for data with a large number of features, more advanced imputation methods may be needed.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ddc839",
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN\n",
        "print(\"One-shot test for Fisher's sharp null using KNN\")\n",
        "KNNimputer = KNNImputer(n_neighbors=7)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=KNNimputer, G2=KNNimputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0d195d",
      "metadata": {},
      "source": [
        "### (iii) BayesianRidge Imputation\n",
        "The BayesianRidge model tries to estimate the coefficients of a linear regression model that best fit the data, taking into account prior knowledge about the coefficients. For data imputation, the missing values are treated as if they are unknown coefficients and are estimated along with the other coefficients during the model fitting process. BayesianRidge can be a good choice for imputation when the relationship between the features is well approximated by a linear model. However, it may not perform well for data sets with more complex relationships between the features.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62280e80",
      "metadata": {},
      "outputs": [],
      "source": [
        "#BayesianRidge\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "BayesianRidge = IterativeImputer(estimator = linear_model.BayesianRidge(),max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=BayesianRidge, G2=BayesianRidge)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012d51ed",
      "metadata": {},
      "source": [
        "### (iv) Nystroem Method for Kernel Approximation\n",
        "The Nystroem method, as implemented in Nystroem is a general method for low-rank approximations of kernels. It achieves this by essentially subsampling the data on which the kernel is evaluated. By default Nystroem uses the rbf kernel, but it can use any kernel function or a precomputed kernel matrix. The number of samples used - which is also the dimensionality of the features computed - is given by the parameter n_components.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fc1e20",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Nystroem Method for Kernel Approximation\n",
        "print(\"One-shot test for Fisher's sharp null using Nystroem Method for Kernel Approximation\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Nystroem(), \n",
        "    linear_model.Ridge()\n",
        ")\n",
        "NystroemKernel = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NystroemKernel, G2=NystroemKernel)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6658f85a",
      "metadata": {},
      "source": [
        "### (V) XGBoost\n",
        "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\n",
        "\n",
        "\n",
        "source - https://xgboost.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457c869e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#XGBoost\n",
        "print(\"One-shot test for Fisher's sharp null using XGBoost\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    xgb.XGBRegressor()\n",
        ")\n",
        "XGBoost = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=XGBoost, G2=XGBoost)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f94fcb",
      "metadata": {},
      "source": [
        "### (vi) MLPRegressor\n",
        "\n",
        "MLPRegressor is a class in the scikit-learn library that implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. It is an artificial neural network model that uses backpropagation to adjust the weights between neurons in order to improve prediction accuracy. MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters. It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b042840a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "print(\"One-shot test for Fisher's sharp null using Neural Network\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MLPRegressor(hidden_layer_sizes=(100, 100, 100), activation='relu', alpha=0.0001, random_state=0)\n",
        ")\n",
        "\n",
        "NN_imputer = IterativeImputer(estimator=pipeline.named_steps['mlpregressor'], max_iter=10, random_state=0)\n",
        "\n",
        "# Assuming the one_shot_test() function is already defined\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NN_imputer, G2=NN_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7d0135",
      "metadata": {},
      "source": [
        "### (vii) Median and Mean Imputer for data imputation\n",
        "\n",
        "Mean and Median as imputed value\n",
        "\n",
        "source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd88c30",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Median imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Median imputer\")\n",
        "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=median_imputer, G2=median_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2883c426",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Mean imputer\")\n",
        "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=mean_imputer, G2=mean_imputer)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d3e2280498d4d0bf5a6eb89edfba29687bb04994b150b07177e7fe6510e612b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

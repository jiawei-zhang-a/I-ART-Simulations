{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a96620bc",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e1fafce2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import random\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import scipy.stats as stats\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03931460",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.733551</td>\n",
              "      <td>1.093402</td>\n",
              "      <td>-0.988934</td>\n",
              "      <td>-0.028470</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.032109</td>\n",
              "      <td>-1.084106</td>\n",
              "      <td>-0.330659</td>\n",
              "      <td>-1.516300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.162402</td>\n",
              "      <td>-1.211182</td>\n",
              "      <td>0.548131</td>\n",
              "      <td>0.421225</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.688071</td>\n",
              "      <td>0.037959</td>\n",
              "      <td>-0.781422</td>\n",
              "      <td>-0.263678</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.382530</td>\n",
              "      <td>-1.396202</td>\n",
              "      <td>0.637463</td>\n",
              "      <td>-0.194021</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.995453</td>\n",
              "      <td>1.845337</td>\n",
              "      <td>0.008771</td>\n",
              "      <td>0.736650</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>-2.338156</td>\n",
              "      <td>2.253895</td>\n",
              "      <td>0.223234</td>\n",
              "      <td>-0.070419</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.385859</td>\n",
              "      <td>-1.046481</td>\n",
              "      <td>-0.784618</td>\n",
              "      <td>-0.851197</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>-0.392338</td>\n",
              "      <td>-1.411726</td>\n",
              "      <td>-0.870114</td>\n",
              "      <td>0.478880</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.782416</td>\n",
              "      <td>-0.360255</td>\n",
              "      <td>-0.060152</td>\n",
              "      <td>0.101786</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3    4\n",
              "0      0.733551  1.093402 -0.988934 -0.028470  0.0\n",
              "1     -0.032109 -1.084106 -0.330659 -1.516300  0.0\n",
              "2      0.162402 -1.211182  0.548131  0.421225  1.0\n",
              "3      1.688071  0.037959 -0.781422 -0.263678  1.0\n",
              "4      0.382530 -1.396202  0.637463 -0.194021  0.0\n",
              "...         ...       ...       ...       ...  ...\n",
              "19995  0.995453  1.845337  0.008771  0.736650  0.0\n",
              "19996 -2.338156  2.253895  0.223234 -0.070419  0.0\n",
              "19997  0.385859 -1.046481 -0.784618 -0.851197  0.0\n",
              "19998 -0.392338 -1.411726 -0.870114  0.478880  0.0\n",
              "19999  0.782416 -0.360255 -0.060152  0.101786  0.0\n",
              "\n",
              "[20000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.330759</td>\n",
              "      <td>12.558827</td>\n",
              "      <td>9.056415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-8.706621</td>\n",
              "      <td>-7.861979</td>\n",
              "      <td>28.608639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.110000</td>\n",
              "      <td>11.653021</td>\n",
              "      <td>5.961538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.887719</td>\n",
              "      <td>26.521297</td>\n",
              "      <td>31.992981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.713080</td>\n",
              "      <td>-0.047184</td>\n",
              "      <td>3.054374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>61.323488</td>\n",
              "      <td>53.983557</td>\n",
              "      <td>174.659981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>1.287464</td>\n",
              "      <td>-1.498519</td>\n",
              "      <td>2.542161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>8.073842</td>\n",
              "      <td>-3.760029</td>\n",
              "      <td>21.446649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>-6.715463</td>\n",
              "      <td>-7.752731</td>\n",
              "      <td>16.948749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>22.210015</td>\n",
              "      <td>7.598422</td>\n",
              "      <td>3.422713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0          1           2\n",
              "0      28.330759  12.558827    9.056415\n",
              "1      -8.706621  -7.861979   28.608639\n",
              "2      34.110000  11.653021    5.961538\n",
              "3      41.887719  26.521297   31.992981\n",
              "4      18.713080  -0.047184    3.054374\n",
              "...          ...        ...         ...\n",
              "19995  61.323488  53.983557  174.659981\n",
              "19996   1.287464  -1.498519    2.542161\n",
              "19997   8.073842  -3.760029   21.446649\n",
              "19998  -6.715463  -7.752731   16.948749\n",
              "19999  22.210015   7.598422    3.422713\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "...   ..\n",
              "19995  1\n",
              "19996  0\n",
              "19997  1\n",
              "19998  0\n",
              "19999  1\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2\n",
              "0      0.0  0.0  0.0\n",
              "1      0.0  0.0  0.0\n",
              "2      0.0  0.0  0.0\n",
              "3      0.0  0.0  1.0\n",
              "4      0.0  0.0  0.0\n",
              "...    ...  ...  ...\n",
              "19995  0.0  0.0  1.0\n",
              "19996  0.0  0.0  0.0\n",
              "19997  0.0  0.0  0.0\n",
              "19998  0.0  0.0  0.0\n",
              "19999  0.0  0.0  0.0\n",
              "\n",
              "[20000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0        1.0\n",
              "1        1.0\n",
              "2        1.0\n",
              "3        1.0\n",
              "4        1.0\n",
              "...      ...\n",
              "19995  100.0\n",
              "19996  100.0\n",
              "19997  100.0\n",
              "19998  100.0\n",
              "19999  100.0\n",
              "\n",
              "[20000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load data\n",
        "X = np.load(\"/Users/jiaweizhang/research/data/X.npy\")\n",
        "Y = np.load(\"/Users/jiaweizhang/research/data/Y.npy\")\n",
        "Z = np.load(\"/Users/jiaweizhang/research/data/Z.npy\")\n",
        "M = np.load(\"/Users/jiaweizhang/research/data/M.npy\")\n",
        "S = np.load(\"/Users/jiaweizhang/research/data/S.npy\")\n",
        "\n",
        "N = len(X)\n",
        "display(pd.DataFrame(X))\n",
        "display(pd.DataFrame(Y))\n",
        "display(pd.DataFrame(Z))\n",
        "display(pd.DataFrame(M))\n",
        "display(pd.DataFrame(S))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab684f3a",
      "metadata": {},
      "source": [
        "# One shot framework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a542e9ca",
      "metadata": {},
      "source": [
        "### Randomly split one dataframe to two datasets\n",
        "split_df takes a pandas DataFrame as input and randomly splits it into two separate DataFrames with a specified proportion of the data in each split. The function shuffles the indices randomly and splits the DataFrame using the shuffled indices. It returns the two separate DataFrames as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a65b62e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#split based on strata\n",
        "def split_df(df,index_S):\n",
        "\n",
        "    # Sort the groups by the number of rows in each group\n",
        "    #sorted_df = df.sort_values(by = index_S, ascending=True)\n",
        "    \n",
        "    # Split the sorted groups into two equal-sized sets of 100 strata each\n",
        "    df_set1 = df.iloc[:int(N/2),0 : index_S]\n",
        "    df_set2 = df.iloc[int(N/2):N, 0 : index_S]\n",
        "\n",
        "    #set the index of the two sets from zero to 1\n",
        "    df_set1.index = range(len(df_set1))\n",
        "    df_set2.index = range(len(df_set2))\n",
        "    \n",
        "    # Return the two sets of strata\n",
        "    return df_set1, df_set2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f937fc0",
      "metadata": {},
      "source": [
        "### T-test for T(Z,Y)\n",
        "the Wilcoxon rank sum test\n",
        "$T(\\mathbf{Z}, \\mathbf{Y})=\\sum_{n=1}^{N}Z_{n}\\cdot \\text{rank}(Y_{n})=\\sum_{n=1}^{N}\\{Z_{n}\\cdot \\sum_{n^{\\prime}=1}^{N} \\mathbf{1}(Y_{n}\\geq Y_{n^{\\prime}})\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "785d184a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def T(z,y):\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    n = len(z)\n",
        "    t = 0\n",
        "    #O(N^2) version\n",
        "    \"\"\"\n",
        "    for n in range(N):\n",
        "        rank = sum(1 for n_prime in range(N) if Y[n] >= Y[n_prime])\n",
        "        T += Z[n] * rank\n",
        "    \"\"\"\n",
        "\n",
        "    #O(N*Log(N)) version\n",
        "    my_list = []\n",
        "    for i in range(n):\n",
        "        my_list.append((z[i],y[i]))\n",
        "    sorted_list = sorted(my_list, key=lambda x: x[1])\n",
        "\n",
        "    #Calculate\n",
        "    for i in range(n):\n",
        "        t += sorted_list[i][0] * (i + 1)\n",
        "    \n",
        "    return t\n",
        "\n",
        "def getT(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    y = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    z = df_imputed[:, 0]\n",
        "    \n",
        "    z_tiled = np.tile(z, 3)\n",
        "\n",
        "    # Concatenate the tiled versions of Z together\n",
        "    new_z = np.concatenate((z_tiled,))\n",
        "    new_y = y.flatten()\n",
        "\n",
        "    #the Wilcoxon rank sum test\n",
        "    t = T(new_z,new_y)\n",
        "\n",
        "    return t\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a89eab",
      "metadata": {},
      "source": [
        "#### t-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5606fc45",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ttest(G, df):\n",
        "    \n",
        "    # Get the imputed data Y and indicator Z\n",
        "    df_imputed = G.transform(df)\n",
        "    Y_pred = df_imputed[:, Z.shape[1] + X.shape[1]:df_imputed.shape[1]]\n",
        "    Z_shuffled = df_imputed[:, 0]\n",
        "\n",
        "    # Get the t-statistics for T(Z,Y)\n",
        "    treatment = Y_pred[Z_shuffled == 1].flatten()\n",
        "    control = Y_pred[Z_shuffled == 0].flatten()\n",
        "\n",
        "    t, p = stats.ttest_ind(treatment, control, equal_var=True)\n",
        "\n",
        "    return t,p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963667c1",
      "metadata": {},
      "source": [
        "## One Short Framework \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "koc_huNCosmJ",
      "metadata": {
        "id": "koc_huNCosmJ"
      },
      "outputs": [],
      "source": [
        "def one_shot_test(Z, X, M, Y, S, G1, G2,  L=10000, verbose = False):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "\n",
        "    #print train start\n",
        "    if verbose:\n",
        "        print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked,S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, X.shape[1] + Y.shape[1] + Z.shape[1])\n",
        "\n",
        "    # re-impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t2_obs = getT(G1, df2)\n",
        "\n",
        "    # re-impute the missing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t1_obs = getT(G2, df1)\n",
        "\n",
        "    #print train end\n",
        "    if verbose:\n",
        "        print(\"Training end\")\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "    \n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "        \n",
        "    \n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G1, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G2, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100\n",
        "            if verbose:  \n",
        "                print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    # calculate exact p-values for each outcome\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "    \n",
        "    return p1, p2\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de036ad6",
      "metadata": {},
      "source": [
        "###  Parallel Computing Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1f0f2f1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def worker(args):\n",
        "    # unpack the arguments\n",
        "    Z, X, M, S, Y_masked, G1, G2, t1_obs, t2_obs, shape, L = args\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros(L)\n",
        "    t2_sim = np.zeros(L)\n",
        "\n",
        "    for l in range(L):\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        df_sim = pd.DataFrame(np.concatenate((X, Y_masked, S), axis=1))\n",
        "        \n",
        "        # split the simulated data into two parts\n",
        "        df1_sim, df2_sim = split_df(df_sim, index_S = X.shape[1] + Y.shape[1])\n",
        "\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z_1 = np.random.binomial(1, 0.5, df1_sim.shape[0]).reshape(-1, 1)\n",
        "        Z_2 = np.random.binomial(1, 0.5, df2_sim.shape[0]).reshape(-1, 1)\n",
        "        df1_sim = pd.concat([pd.DataFrame(Z_1), df1_sim], axis=1)\n",
        "        df2_sim = pd.concat([pd.DataFrame(Z_2), df2_sim], axis=1)\n",
        "\n",
        "        # get the test statistics in part 1\n",
        "        t1_sim[l] = getT(G2, df1_sim)\n",
        "\n",
        "        # get the test statistics in part 2\n",
        "        t2_sim[l] = getT(G1, df2_sim)\n",
        "\n",
        "        # Calculate the completeness percentage\n",
        "        if l % 100 == 0:\n",
        "            completeness = l / L * 100  \n",
        "            print(f\"Task is {completeness:.2f}% complete.\")\n",
        "\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "\n",
        "    return p1, p2\n",
        "\n",
        "def one_shot_test_parallel(Z, X, M, Y, S, G1, G2, L=10000, n_jobs=multiprocessing.cpu_count()):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "    #print train start\n",
        "    print(\"Training start\")\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked, S), axis=1))\n",
        "    \n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df, index_S = Z.shape[1] + X.shape[1] + Y.shape[1])\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    t1_obs = getT(G1, df2)\n",
        "\n",
        "    # impute the miassing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    t2_obs = getT(G2, df1)\n",
        "\n",
        "    #print train end\n",
        "    print(\"Training end\")\n",
        "    \n",
        "    # print the number of cores\n",
        "    print(f\"Number of cores: {n_jobs}\")\n",
        "\n",
        "\n",
        "    # simulate data and calculate test statistics in parallel\n",
        "    args_list = [(Z, X, M, Y_masked, S, G1, G2, t1_obs, t2_obs, df.shape, int(L / n_jobs))] * n_jobs\n",
        "    with multiprocessing.Pool(processes=n_jobs) as pool:\n",
        "        p_list = pool.map(worker, args_list)\n",
        "    p1 = np.mean([p[0] for p in p_list], axis=0)\n",
        "    p2 = np.mean([p[1] for p in p_list], axis=0)\n",
        "    \n",
        "    return p1, p2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9594bc22",
      "metadata": {},
      "source": [
        "# Test the framework \n",
        "\n",
        "Test all the machine learning method in single core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06073b6",
      "metadata": {},
      "source": [
        "### (i)  MissForest\n",
        "missForest is an algorithm for data imputation, which is the process of filling in missing values in a dataset. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer.\n",
        "\n",
        "missForest is an implementation of the random forest algorithm for missing data imputation. The algorithm works by building an ensemble of decision trees to predict the missing values in a dataset. The idea behind the algorithm is that decision trees can be used to model the relationship between the variables in a dataset and can be used to predict missing values. The algorithm works by splitting the dataset into several smaller datasets, building decision trees on each of these smaller datasets, and combining the predictions from these decision trees to obtain a final imputed dataset.\n",
        "\n",
        "One of the advantages of using missForest is that it can handle missing values in both categorical and continuous variables. It also handles data with different missing patterns and can be used to impute multiple imputations at once. Additionally, missForest provides a measure of the imputation uncertainty, which is important for correctly interpreting the results of the imputed data. \n",
        "\n",
        "source - https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "105e3d5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot test for Fisher's sharp null using MissForest\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f1d6baeb20f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmissForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_shot_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissForest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissForest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p-values for part 1:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p-values for part 2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-520980f27689>\u001b[0m in \u001b[0;36mone_shot_test\u001b[0;34m(Z, X, M, Y, S, G1, G2, L, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# get the test statistics in part 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mt2_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Calculate the completeness percentage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-97e0a97b3681>\u001b[0m in \u001b[0;36mgetT\u001b[0;34m(G, df)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Get the imputed data Y and indicator Z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf_imputed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_missing_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mX_indicator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36m_initial_imputation\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         X = self._validate_data(X, dtype=FLOAT_DTYPES, order=\"F\", reset=in_fit,\n\u001b[0m\u001b[1;32m    513\u001b[0m                                 force_all_finite=force_all_finite)\n\u001b[1;32m    514\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             if (not hasattr(array, 'sparse') and\n\u001b[0;32m--> 514\u001b[0;31m                     array.dtypes.apply(is_sparse).any()):\n\u001b[0m\u001b[1;32m    515\u001b[0m                 warnings.warn(\n\u001b[1;32m    516\u001b[0m                     \u001b[0;34m\"pandas.DataFrame with sparse columns found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4135\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4137\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4138\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5876\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5877\u001b[0m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5880\u001b[0m         \u001b[0;31m# GH 33113: handle empty frame or series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5433\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5436\u001b[0m             \u001b[0;31m# For subclasses using _metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5437\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/flags.py\u001b[0m in \u001b[0;36mallows_duplicate_labels\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This flag's object has been deleted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#MissForest\n",
        "print(\"One-shot test for Fisher's sharp null using MissForest\")\n",
        "missForest_1 = IterativeImputer(estimator = RandomForestRegressor(),max_iter=10, random_state=0)\n",
        "missForest_2 = IterativeImputer(estimator = RandomForestRegressor(),max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S,G1=missForest_1, G2=missForest_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e6ca0919",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  0             1             2             3             4  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       0.500000      0.492474     -0.333316     -0.004549      0.563202   \n",
            "std        0.500013      0.993959      1.005727      1.008446      1.009812   \n",
            "min        0.000000     -4.184874     -4.337442     -8.626627     -6.334093   \n",
            "25%        0.000000     -0.182269     -0.996122     -0.501102      0.072906   \n",
            "50%        0.500000      0.496718     -0.339506     -0.001853      0.572347   \n",
            "75%        1.000000      1.163361      0.339355      0.489165      1.054114   \n",
            "max        1.000000      4.625756      4.282537      6.337571      6.297321   \n",
            "\n",
            "                  5             6             7              8             9  \n",
            "count  20000.000000  20000.000000  20000.000000   14586.000000  20000.000000  \n",
            "mean       0.330100     27.625327     32.443883     248.372720     99.520000  \n",
            "std        0.470261     68.021646    135.406765    1613.637327     57.735918  \n",
            "min        0.000000  -1117.011591    -40.508469      -4.320799      0.000000  \n",
            "25%        0.000000      2.210735     -1.422833       6.293922     50.000000  \n",
            "50%        0.000000     17.365010     10.377250      34.476897    100.000000  \n",
            "75%        1.000000     36.560539     32.423300     137.801172    150.000000  \n",
            "max        1.000000   2290.784649   8551.654387  106637.266971    200.000000  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "def demo(Z, X, M, Y, S):\n",
        "\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked,S), axis=1))\n",
        "    return df\n",
        "\n",
        "df = demo(Z, X, M, Y, S)\n",
        "df[:100].to_csv(\"demo.csv\")\n",
        "\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d600ae6f",
      "metadata": {},
      "source": [
        "### (ii) KNN Imputation\n",
        "The basic idea behind KNN for imputation is to replace missing values with the average of the k-nearest neighbors in the feature space. The value of k is determined by the user and can be set using cross-validation. KNN imputation is considered a simple and effective method for imputing missing data, particularly for small amounts of missing values. However, for larger amounts of missing data or for data with a large number of features, more advanced imputation methods may be needed.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ddc839",
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN\n",
        "print(\"One-shot test for Fisher's sharp null using KNN\")\n",
        "KNNimputer_1 = KNNImputer(n_neighbors=7)\n",
        "KNNimputer_2 = KNNImputer(n_neighbors=7)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=KNNimputer_1, G2=KNNimputer_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0d195d",
      "metadata": {},
      "source": [
        "### (iii) BayesianRidge Imputation\n",
        "The BayesianRidge model tries to estimate the coefficients of a linear regression model that best fit the data, taking into account prior knowledge about the coefficients. For data imputation, the missing values are treated as if they are unknown coefficients and are estimated along with the other coefficients during the model fitting process. BayesianRidge can be a good choice for imputation when the relationship between the features is well approximated by a linear model. However, it may not perform well for data sets with more complex relationships between the features.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62280e80",
      "metadata": {},
      "outputs": [],
      "source": [
        "#BayesianRidge\n",
        "print(\"One-shot test for Fisher's sharp null\")\n",
        "BayesianRidge_1 = IterativeImputer(estimator = linear_model.BayesianRidge(),max_iter=10, random_state=0)\n",
        "BayesianRidge_2 = IterativeImputer(estimator = linear_model.BayesianRidge(),max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=BayesianRidge_1, G2=BayesianRidge_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012d51ed",
      "metadata": {},
      "source": [
        "### (iv) Nystroem Method for Kernel Approximation\n",
        "The Nystroem method, as implemented in Nystroem is a general method for low-rank approximations of kernels. It achieves this by essentially subsampling the data on which the kernel is evaluated. By default Nystroem uses the rbf kernel, but it can use any kernel function or a precomputed kernel matrix. The number of samples used - which is also the dimensionality of the features computed - is given by the parameter n_components.\n",
        "\n",
        "Source - https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fc1e20",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Nystroem Method for Kernel Approximation\n",
        "print(\"One-shot test for Fisher's sharp null using Nystroem Method for Kernel Approximation\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Nystroem(), \n",
        "    linear_model.Ridge()\n",
        ")\n",
        "NystroemKernel_1 = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "NystroemKernel_2 = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NystroemKernel_1, G2=NystroemKernel_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6658f85a",
      "metadata": {},
      "source": [
        "### (V) XGBoost\n",
        "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\n",
        "\n",
        "\n",
        "source - https://xgboost.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457c869e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#XGBoost\n",
        "print(\"One-shot test for Fisher's sharp null using XGBoost\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    xgb.XGBRegressor()\n",
        ")\n",
        "XGBoost_1 = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "XGBoost_2 = IterativeImputer(estimator = pipeline,max_iter=10, random_state=0)\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=XGBoost_1, G2=XGBoost_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f94fcb",
      "metadata": {},
      "source": [
        "### (vi) MLPRegressor\n",
        "\n",
        "MLPRegressor is a class in the scikit-learn library that implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. It is an artificial neural network model that uses backpropagation to adjust the weights between neurons in order to improve prediction accuracy. MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters. It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b042840a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "print(\"One-shot test for Fisher's sharp null using Neural Network\")\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MLPRegressor(hidden_layer_sizes=(100, 100, 100), activation='relu', alpha=0.0001, random_state=0)\n",
        ")\n",
        "\n",
        "NN_imputer_1 = IterativeImputer(estimator=pipeline.named_steps['mlpregressor'], max_iter=10, random_state=0)\n",
        "NN_imputer_2 = IterativeImputer(estimator=pipeline.named_steps['mlpregressor'], max_iter=10, random_state=0)\n",
        "\n",
        "# Assuming the one_shot_test() function is already defined\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=NN_imputer_1, G2=NN_imputer_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7d0135",
      "metadata": {},
      "source": [
        "### (vii) Median and Mean Imputer for data imputation\n",
        "\n",
        "Mean and Median as imputed value\n",
        "\n",
        "source - https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd88c30",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Median imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Median imputer\")\n",
        "median_imputer_1 = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "median_imputer_2 = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=median_imputer_1, G2=median_imputer_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2883c426",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mean imputer\n",
        "print(\"One-shot test for Fisher's sharp null using Mean imputer\")\n",
        "mean_imputer_1 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "mean_imputer_2 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "p1, p2 = one_shot_test(Z, X, M, Y, S, G1=mean_imputer_1, G2=mean_imputer_2)\n",
        "print(\"p-values for part 1:\", p1)\n",
        "print(\"p-values for part 2:\", p2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d3e2280498d4d0bf5a6eb89edfba29687bb04994b150b07177e7fe6510e612b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
